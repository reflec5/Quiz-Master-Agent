# Quiz Master Agent ğŸ“

## Project Description
The **Quiz Master Agent** is an AI-powered study helper designed to transform raw educational text into interactive multiple-choice quizzes. By leveraging a Large Language Model (LLM) via API, the agent understands complex text, identifies key concepts, and generates structured assessment data (questions, options, correct answers, and explanations).

This project demonstrates the implementation of an AI agent that can:
1.  **Interpret User Inputs:** Accepts natural language notes or articles.
2.  **Generate Structured Prompts:** Forces the LLM to output strict JSON data rather than conversational text.
3.  **Validate & Parse Outputs:** Includes a robust validation layer to ensure quiz integrity (e.g., verifying the correct answer exists in the options).
4.  **Execute Follow-up Actions:** Automatically grades user attempts and provides immediate feedback with reasoning.

## ğŸ“‚ File Structure

The project follows a modular architecture separating the Frontend (UI) from the Backend (Agent Logic).

```text
quiz_master_agent/
â”‚
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ secrets.toml      # (Ignored by Git) Stores sensitive API Keys & Endpoint URLs
â”‚
â”œâ”€â”€ app.py                # The Frontend. Handles UI layout, session state, and user interaction.
â”‚
â”œâ”€â”€ agent_logic.py        # The Backend. Handles API communication, prompt engineering, and JSON validation.
â”‚
â”œâ”€â”€ requirements.txt      # List of Python dependencies.
â”‚
â””â”€â”€ README.md             # Project documentation.
```

## âœ¨ Key Features

* **RAG-Lite Workflow**: Takes external source text (User Notes) and augments generation based strictly on that context.

* **JSON Mode Enforcement**: Uses specific prompt engineering techniques to guarantee machine-readable output from the LLM.

* **Auto-Correction Logic**: A Python-based validation layer (validate_and_fix_quiz) ensures the LLM never generates a "broken" question where the correct answer is missing from the choices.

* **Session State Management**: Uses Streamlit Session State to persist quiz data across UI re-renders without needing an external database.

## ğŸš€ Setup & Installation

### 1. Prerequisites

  * Python 3.8 or higher

  * An active API Key (for the Class LLM Service or OpenAI)

### 2. Install Dependencies

Open a terminal in the project folder and run:
```Bash
pip install -r requirements.txt
```

### 3. Configure API Credentials

Create a folder named `.streamlit` and a file inside it named `secrets.toml`:

```Ini, TOML
.streamlit/secrets.toml
LLM_API_KEY = "your-api-key-here"
```

(Note: This file is excluded from version control to prevent security leaks.)
## ğŸ•¹ï¸ Usage Guide

### Start the Agent:

Run the following command in your terminal:
```Bash
streamlit run app.py
```

### Interact:

*    The browser will open to http://localhost:8501.

*    **Input**: Paste a paragraph of text (e.g., lecture notes, a Wikipedia summary, or code documentation) into the text area.

*    **Settings**: Adjust the difficulty and number of questions in the sidebar.

*    **Generate**: Click "Generate Quiz."

### Take the Quiz:

*    Select an answer for each question.

*    Click "Check Answer" to receive immediate grading and an explanation generated by the AI.

## ğŸ› ï¸ Implementation Details (For Report)

* Prompt Engineering:
We utilized a "System Persona" to enforce the role of a teacher. We used "Few-Shot" formatting instructions to ensure the output complied with our JSON schema `[{"question": "...", "options": [...]}]`.

* Challenges Overcome:

  * **Hallucination**: The LLM occasionally omitted the correct answer from the options list. We implemented a deterministic Python function to check for this and inject the correct answer if missing.

  * **Formatting**: The LLM sometimes included Markdown backticks (```json) in the response. We added a string cleaning step before JSON parsing.
