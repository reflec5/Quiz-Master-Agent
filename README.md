# Quiz Master Agent üéì

## Project Description
The **Quiz Master Agent** is an AI-powered study helper designed to transform raw educational text into interactive multiple-choice quizzes. By leveraging a Large Language Model (LLM) via API, the agent understands complex text, identifies key concepts, and generates structured assessment data (questions, options, correct answers, and explanations).

This project demonstrates the implementation of an AI agent that can:
1.  **Interpret User Inputs:** Accepts natural language notes or articles.
2.  **Generate Structured Prompts:** Forces the LLM to output strict JSON data rather than conversational text.
3.  **Validate & Parse Outputs:** Includes a robust validation layer to ensure quiz integrity (e.g., verifying the correct answer exists in the options).
4.  **Execute Follow-up Actions:** Automatically grades user attempts and provides immediate feedback with reasoning.

## üìÇ File Structure

The project follows a modular architecture separating the Frontend (UI) from the Backend (Agent Logic).

```text
quiz_master_agent/
‚îÇ
‚îú‚îÄ‚îÄ .streamlit/
‚îÇ   ‚îî‚îÄ‚îÄ secrets.toml      # (Ignored by Git) Stores sensitive API Keys & Endpoint URLs
‚îÇ
‚îú‚îÄ‚îÄ app.py                # The Frontend. Handles UI layout, session state, and user interaction.
‚îÇ
‚îú‚îÄ‚îÄ agent_logic.py        # The Backend. Handles API communication, prompt engineering, and JSON validation.
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt      # List of Python dependencies.
‚îÇ
‚îî‚îÄ‚îÄ README.md             # Project documentation.
```

## ‚ú® Key Features

* **RAG-Lite Workflow**: Takes external source text (User Notes) and augments generation based strictly on that context.

* **JSON Mode Enforcement**: Uses specific prompt engineering techniques to guarantee machine-readable output from the LLM.

* **Auto-Correction Logic**: A Python-based validation layer (validate_and_fix_quiz) ensures the LLM never generates a "broken" question where the correct answer is missing from the choices.

* **Session State Management**: Uses Streamlit Session State to persist quiz data across UI re-renders without needing an external database.

* **User Customization**: Aside from user text, user may finetune questions styles to their likings by adding their own prompts.

## üöÄ Setup & Installation

### 1. Prerequisites

  * Python 3.8 or higher

  * An active API Key (for the Class LLM Service or OpenAI)

### 2. Install Dependencies

Open a terminal in the project folder and run:
```Bash
pip install -r requirements.txt
```

### 3. Configure API Credentials

Create a folder named `.streamlit` and a file inside it named `secrets.toml`:

```Ini, TOML
.streamlit/secrets.toml
LLM_API_KEY = "your-api-key-here"
```

(Note: This file is excluded from version control to prevent security leaks.)
## üïπÔ∏è Usage Guide

### Start the Agent:

Run the following command in your terminal:
```Bash
streamlit run app.py
```

### Interact:

*    The browser will open to http://localhost:8501.

*    **Input**: Paste a paragraph of text (e.g., lecture notes, a Wikipedia summary, or code documentation) into the text area.

*    **Settings**: Adjust the difficulty and number of questions in the sidebar.

*    **Generate**: Click "Generate Quiz."

### Take the Quiz:

*    Select an answer for each question.

*    Click "Check Answer" to receive immediate grading and an explanation generated by the AI.

## ‚öôÔ∏è Detailed Workflow and Implementation

The Quiz Master Agent operates on a linear, state-driven architecture. The system processes user inputs through a specialized pipeline designed to ensure data integrity and output relevance.

### 1. Input Acquisition Phase

* **Data Ingestion**: The user provides unstructured text (e.g., lecture notes, articles) via the Streamlit interface.

* **Parameter Configuration**: The user selects constraints via the sidebar:

    * _Difficulty_ (Easy/Medium/Hard)

    * _Quiz Length_ (1~5 Note: Kept short to maintain response quality) 

    * _Custom Directives_ (e.g., "Focus on Chapter 3")

### 2. The Agent Processing Phase (Backend)

The `agent_logic.py` module acts as the orchestration layer. It does not simply forward text; it actively constructs the task.

* **Prompt Construction**: The agent dynamically builds a system prompt that injects the user's configuration and enforces a strict JSON schema.

   * *System Persona*: "You are a Teacher AI..."

   * *Constraint Injection*: "Output ONLY raw JSON..."

* **API Interaction**: The constructed payload is sent to the LLM (Ollama) via a synchronous HTTP POST request.

* **JSON Enforcement**: The agent requests `json_mode` (where supported) to minimize parsing errors.

### 3. Validation & Self-Correction Layer

This is the critical "Intelligent" component that distinguishes the system from a simple chatbot. Before the user sees the result, the system performs Deterministic Verification:

* **Structure Check**: Parses the string response into a Python dictionary. If parsing fails, it catches the error gracefully.

* **Logic Validation**: Iterates through every generated question to verify that the string in the `"answer"` field exists exactly within the `"options"` list.

* **Auto-Correction**: If the LLM "hallucinates" (provides an answer not listed in the options), the validation layer programmatically injects the correct answer into the options list, ensuring the quiz is always solvable.

### 4. Output & State Management Phase

* **State Serialization**: The validated quiz data is stored in Streamlit's `session_state`. This allows the application to re-render (e.g., when a user clicks a button) without losing the quiz data.

* **Interactive Rendering**: The frontend parses the JSON to generate UI widgets (Radio Buttons).

* **Feedback Loop**: When a user submits an answer, the system compares it against the stored correct value and reveals the `"explanation"` field generated by the LLM, completing the learning loop.
